# torch.optim.Adam をインスタンス化するよう指定。
# Python側で `hydra.utils.instantiate(cfg.optimizer, params=model.parameters())` 
# のように呼び出すことで、params以外の引数(lr, weight_decay)が渡される。
name: adam

params:
  lr: 0.0005 #変更前：0.001
  betas:
    - 0.9
    - 0.999
  eps: 1e-08
  weight_decay: 0.0001
  amsgrad: false