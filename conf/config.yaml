# (例: model=resnet とすれば、resnet.yamlを読み込む)
defaults:
  - _self_
  - model: simplecnn #モデル設定（simplecnn or resnet)
  - optimizer: adam
  - lr_scheduler: multi_step

# --- コマンドライン引数のデフォルト値 ---
# python train.py args.seed=123` のようにアクセス・上書きできる。
args:
  history_dir: "./outputs/train/history"
  seed: 42
  skip_tested: false
  
# --- 訓練全体に関わる設定 ---
seed: 50 #再現性確保のため、固定値を採用
epoch: 100 # 訓練エポック数

# --- データローダー設定 ---
dataloader: 
  batch_size: 64  # ← 256 から減らす（64：SimpleCNN、32：ResNet）
  num_workers: 2  # ← 16 から減らす 同様の理由
  pin_memory: true

# --- データセット設定 ---
dataset:
#  評価・評価データセットの設定 
  train:
    _target_: src.dataset.AnnotatedDatasetFolder
    #評価用のアノテーションCSVファイル（ない場合は null を指定）
    annotation_file: "conf/dataset/annotations.csv" # or null
    #評価用の画像フォルダ
    root: "conf/dataset/HDR_subdataset"
    loader: #画像を読み込むためのloaderを追加
      _target_: src.dataset.pil_loader
      # 訓練時の変数処理パラメータ
    transform:
      _target_: torchvision.transforms.v2.Compose
      transforms:
        - _target_: torchvision.transforms.v2.ToImage
        - _target_: torchvision.transforms.v2.RandomResizedCrop
          size: 224
        - _target_: torchvision.transforms.v2.RandomHorizontalFlip
          p: 0.5
        - _target_: torchvision.transforms.v2.RandomRotation
          degrees: 15
        - _target_: torchvision.transforms.v2.RandomVerticalFlip
          p: 0.5
        - _target_: torchvision.transforms.v2.ToDtype
          dtype: ${to_dtype:torch.float32} # 文字列を本物のtorch.float32型に変換
          scale: true
        - _target_: torchvision.transforms.v2.Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]

# 訓練/検証の自動分割設定 (80%を訓練、20%を検証に使用)
  split:
    val_size: 0.2
    random_state: 42

  # --- 評価（試験）用のデータセット設定 ---
  test:
    _target_: src.dataset.AnnotatedDatasetFolder
    #評価専用の画像フォルダ 変更必須←同じ画像群を用いているため。本来以上の精度が出る
    root: "conf/dataset/HDR_subdataset"
    # 評価専用のアノテーションCSV（ラベルなし予測のみならnull）
    annotation_file: null
    loader:
      _target_: src.dataset.pil_loader
    # 評価時にはデータ拡張を最小限に
    transform:
      _target_: torchvision.transforms.v2.Compose
      transforms:
        - _target_: torchvision.transforms.v2.ToImage
        - _target_: torchvision.transforms.v2.Resize
          size: 256
        - _target_: torchvision.transforms.v2.CenterCrop
          size: 224
        - _target_: torchvision.transforms.v2.ToDtype
          dtype: ${to_dtype:torch.float32}
          scale: true
        - _target_: torchvision.transforms.v2.Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]


  #---Optuna1とHydraの設定---
optuna:
  direction: maximize
  n_trials: 100
  sampler:
    _target_: optuna.samplers.TPESampler
hydra:
  run:
    dir: ./
  output_subdir: null
  job_logging:
    version: 1
    handlers:
      console:
        class: logging.StreamHandler
        stream: ext://sys.stdout
    root:
      handlers: [console]
    disable_existing_loggers: false
        
