defaults:
  - _self_
  - dataset: annotated
  - model: simplecnn #simplecnn　または resnet
  - optimizer: adam
  - lr_scheduler: multi_step
seed: 50 #再現性確保のため、固定値を採用

dataloader: 
  batch_size: 64  # ← 256 から減らす（64：SimpleCNN、32：ResNet）(5月20日)
  num_workers: 2  # ← 16 から減らす
  pin_memory: true

epoch: 100 # 時間削減のため200→100へ変更
          #ResNetの際には、時間的考慮で20に変更
        #---データセットの指定---
dataset:
  # --- 訓練・検証用データセットの設定 ---
  train:
    _target_: src.dataset.AnnotatedDatasetFolder
    # ★★要変更★★: 訓練・検証用のアノテーションCSVファイル
    annotation_file: "path/to/your/annotations.csv" 
    # ★★要変更★★: 訓練・検証用の画像フォルダ
    root: "path/to/your/training_images"       
    
    loader:
      _target_: src.dataset.pil_loader

    transform:
    #データ拡張（8/05）画像変換の設定を変更
      _target_: torchvision.transform.v2.Compose
      transforms:
        - _target_: torchvision.transforms.v2.ToImage
        - _target_: torchvision.transforms.v2.RandomResizedCrop #ランダムに切り抜いてリサイズする
          size: 224 #モデルの入力サイズに合わせて調整
        - _target_: torchvision.transforms.v2.RandomHorizontalFlip #左右反転
          p: 0.5
        - _target_: torchvision.transforms.RandomRotation #回転
          degrees: 15
        - _target_: torchvision.transforms.RandomVerticalFlip #上下反転
          p: 0.5
        - _target_: torchvision.transforms.v2.ToDtype #テンソルに変換
          dtype: ${torch.float32}
          scale: True
        - _target_: torchvision.transforms.v2.Normalize #ピクセル値を正規化して、モデルが学習
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    
  # 学習・検証データ分割の設定 (例: 全3640件を3000件の学習と640件の検証に分割)
  random_split:
    lengths: [3000, 640] #変更前lengths: [40000, 10000]

#  評価（試験）用データセットの設定 
  test:
    _target_: src.dataset.AnnotatedDatasetFolder
    #評価用の画像フォルダ
    root: "path/to/your/test_images"
    #評価用のアノテーションCSVファイル（ない場合は null を指定）
    annotation_file: "path/to/your/test_annotations.csv" # or null

     # 評価時にはデータ拡張を行わない変換処理
    transform:
      _target_: torchvision.transforms.v2.Compose
      transforms:
        - _target_: torchvision.transforms.v2.ToImage
        - _target_: torchvision.transforms.v2.Resize
          size: [224, 224] # 学習時とサイズを合わせる
        - _target_: torchvision.transforms.v2.ToDtype
          dtype: ${torch.float32}
          scale: True
        - _target_: torchvision.transforms.v2.Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]

          
  #---Optuna1とHydraの設定---
optuna:
  direction: maximize
  n_trials: 100
  sampler:
    _target_: optuna.samplers.TPESampler
hydra:
  run:
    dir: ./
  output_subdir: null
  job_logging:
    version: 1
    handlers:
      console:
        class: logging.StreamHandler
        stream: ext://sys.stdout
    root:
      handlers: [console]
    disable_existing_loggers: false